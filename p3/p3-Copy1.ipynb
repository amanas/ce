{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Bibliografía:\n",
    "  - El **tema 6** permitirá al alumno familiarizarse con la programación genética (PG) \n",
    "  - y, **el mencionado artículo**, con una de las variantes de la PG, denominada Evolución Gramatical (del inglés Grammatical Evolution, GE). \n",
    "  - El **capítulo 8** describe distintos mecanismos para sintonizar de forma adaptativa cada uno de los diferentes parámetros de los que consta un algoritmo evolutivo (AE). \n",
    "  - El **capítulo 10** describe la forma de hibridar un AE con otros métodos de búsqueda. \n",
    "  - Finalmente, en el **capítulo 12**, se muestran distintas estrategias para manejar la existencia de restricciones en problemas de optimización que son abordados mediante AEs.\n",
    "  \n",
    "2. Secciones\n",
    "  - Descripción del problema a resolver\n",
    "  - Método para resolverlo \n",
    "    - se debe analizar la idoneidad o no del uso de GE para resolver el problema planteado\n",
    "    - se debe incluir la expresión matemática de la función de evaluación finalmente empleada\n",
    "    - se debe incluir la descripción de los diferentes operadores de inicialización, variación y selección empleados\n",
    "    - se debe incluir la forma de manejar las restricciones, los mecanismos de control de parámetros utilizados, así como los mecanismos de búsqueda local implementados\n",
    "  - Los resultados de los distintos experimentos realizados\n",
    "  - Un análisis y comparación de resultados\n",
    "  - Una sección de conclusiones\n",
    "  - Una descripción del código implementado. \n",
    "\n",
    "3. Evaluación\n",
    "  - Sobre la presentación (2/10)\n",
    "    - Se evaluará especialmente la claridad en la redacción de la memoria y la capacidad de síntesis.  \n",
    "  - Sobre el manejo de restricciones (1/10)\n",
    "      - Se valorará la originalidad del mecanismo o mecanismos usados para el manejo de restricciones.\n",
    "  - Sobre la configuración del algoritmo (2/10)\n",
    "    - Aquí se valorará el procedimiento seguido por el alumno a la hora de elegir la mejor configuración de parámetros del algoritmo, incluyendo la implementación de mecanismos de control de parámetros adaptativos o auto-adaptativos\n",
    "  - Sobre la hibridación del algoritmo con técnicas de búsqueda local (1/10)\n",
    "    - Se valorará la originalidad del mecanismo de búsqueda local utilizado.\n",
    "  - Sobre el análisis y comparación de resultados, y conclusiones (4/10)\n",
    "    - Se valorará la forma de interpretar y comparar los diferentes experimentos realizados.\n",
    "      - Es muy importante que dicha valoración se haga siempre en términos de los índices SR, MBF, AES \n",
    "      - y cualquier otra gráfica que considere oportuna como, por ejemplo, los plots de progreso de convergencia. \n",
    "    - Finalmente, se valorará la calidad de las conclusiones obtenidas a partir de la interpretación y comparación de resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Descripción del problema a resolver\n",
    "\n",
    "Repitiendo las indicaciones dadas en el documento de la actividad, el problema consiste en implementar un algoritmo evolutivo para calcular la derivada simbólica de una función \n",
    "$$ f:X \\subseteq \\mathcal{R} \\rightarrow \\mathcal{R} $$ \n",
    "\n",
    "Disponemos de las siguientes dos definiciones:\n",
    "\n",
    "> **Definición de derivada de una función en un punto**: Sea $X \\subseteq \\mathcal{R}$ un intervalo abierto. Diremos que $f:X \\subseteq \\mathcal{R} \\rightarrow \\mathcal{R}$ es derivable en $x_0 \\in X$, denotado por $f'(x_0)$, si existe y es finito el límite:\n",
    "$$\n",
    "f'(x_0) = \\lim \\limits_{h \\to 0} \\frac{f(x_0+h)-f(x_0)}{h}  \\tag{1}\n",
    "$$\n",
    "\n",
    "> **Definición de derivada de una función en un intervalo**: Sea $X \\subseteq \\mathcal{R}$ un intervalo abierto. Diremos que $f:X \\subseteq \\mathcal{R} \\rightarrow \\mathcal{R}$ es derivable en el intervalo $[a,b] \\subseteq X$, si $f$ es derivable en cada uno de los puntos de dicho intervalo, es decir, si:\n",
    "$$\n",
    "f'(x) = \\lim \\limits_{h \\to 0} \\frac{f(x+h)-f(x)}{h}, \\forall x \\in [a,b]  \\tag{2}\n",
    "$$\n",
    "\n",
    "Suponiendo que $f$ sea derivable en $[a,b]$, el problema de calcular la derivada lo vamos a transformar en un nuevo problema de optimización consistente en encontrar una función $g(x)$ que minimice la expresión:\n",
    "$$\n",
    "\\min \\limits_{g(x)} \\frac{1}{b-a}\\int_{a}^{b} error[f'(x),g(x)]dx \\tag{3}\n",
    "$$\n",
    "\n",
    "dónde $f'(x)$ se calcularía utilizando la expresión $(2)$.\n",
    "\n",
    "No obstante, el problema anterior se puede resolver de forma aproximada discretizando el intervalo de definición, es decir, cambiando el operador integral por un sumatorio:\n",
    "$$\n",
    "\\min \\limits_{g(x)} \\frac{1}{N+1}\\sum_{i=0}^{N} error_i[f'(a+i*h),g(a+i*h)] \\tag{4}\n",
    "$$\n",
    "dónde $h=\\frac{b-a}{N}$ es la anchura del subintervalo de muestreo para conseguir muestrear $N+1$ puntos en el intervalo $[a,b]$, y $f'(a+i*h)$ viene dado por:\n",
    "$$\n",
    "f'(a+i*h)=\\frac{f(a+(i+1)*h) - f(a+i*h)}{h}, \\forall i \\in \\{0,1,...,N\\} \\tag{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.  Método para resolverlo\n",
    "\n",
    "##2.1. Idoneidad de GE para resolver el problema\n",
    "\n",
    "La estrategia utilizada para la resolución de este problema consiste en elgir un conjunto de familias de funciones con dominio $ [a,b] $ e implementar un algoritmo de búsqueda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#\n",
    "#   Copyright (C) 2008  Don Smiley  ds@sidorof.com\n",
    "\n",
    "#   This program is free software: you can redistribute it and/or modify\n",
    "#   it under the terms of the GNU General Public License as published by\n",
    "#   the Free Software Foundation, either version 3 of the License, or\n",
    "#   (at your option) any later version.\n",
    "\n",
    "#   This program is distributed in the hope that it will be useful,\n",
    "#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#   GNU General Public License for more details.\n",
    "\n",
    "#   You should have received a copy of the GNU General Public License\n",
    "#   along with this program.  If not, see <http://www.gnu.org/licenses/>\n",
    "\n",
    "#   See the LICENSE file included in this archive\n",
    "#\n",
    "\n",
    "\"\"\"\n",
    "This sample program shows a simple use of grammatical evolution.  The\n",
    "evolutionary process drives the fitness values towards zero.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pyneurgen.grammatical_evolution import GrammaticalEvolution\n",
    "from pyneurgen.fitness import FitnessElites, FitnessTournament\n",
    "from pyneurgen.fitness import ReplacementTournament, MAX, MIN, CENTER\n",
    "\n",
    "\n",
    "bnf =   \"\"\"\n",
    "<expr>              ::= <expr> <biop> <expr> | <uop> <expr> | <real> \n",
    "                      | math.log(abs(<expr>)) | <pow> | math.sin(<expr> )\n",
    "                      | value | (<expr>)\n",
    "<biop>              ::= + | - | * | /\n",
    "<uop>               ::= + | -\n",
    "<pow>               ::= pow(<expr>, <real>)\n",
    "<plus>              ::= +\n",
    "<minus>             ::= -\n",
    "<real>              ::= <int-const>.<int-const>\n",
    "<int-const>         ::= <int-const> | 1 | 2 | 3 | 4 | 5 | 6 |\n",
    "                        7 | 8 | 9 | 0\n",
    "<S>                 ::=\n",
    "import math\n",
    "total = 0.0\n",
    "for i in xrange(100):\n",
    "    value = float(i) / float(100)\n",
    "    total += abs(<expr> - pow(value, 3))\n",
    "fitness = total\n",
    "self.set_bnf_variable('<fitness>', fitness)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "ges = GrammaticalEvolution()\n",
    "\n",
    "ges.set_bnf(bnf)\n",
    "ges.set_genotype_length(start_gene_length=20,\n",
    "                        max_gene_length=50)\n",
    "ges.set_population_size(50)\n",
    "ges.set_wrap(True)\n",
    "\n",
    "ges.set_max_generations(10)\n",
    "ges.set_fitness_type(MIN, .01)\n",
    "\n",
    "ges.set_max_program_length(100)\n",
    "ges.set_timeouts(10, 120)\n",
    "ges.set_fitness_fail(100.0)\n",
    "\n",
    "ges.set_mutation_rate(.025)\n",
    "ges.set_fitness_selections(\n",
    "    FitnessElites(ges.fitness_list, .05),\n",
    "    FitnessTournament(ges.fitness_list, tournament_size=2))\n",
    "ges.set_max_fitness_rate(.5)\n",
    "\n",
    "ges.set_crossover_rate(.2)\n",
    "ges.set_children_per_crossover(2)\n",
    "ges.set_mutation_type('m')\n",
    "ges.set_max_fitness_rate(.25)\n",
    "\n",
    "ges.set_replacement_selections(\n",
    "        ReplacementTournament(ges.fitness_list, tournament_size=3))\n",
    "\n",
    "ges.set_maintain_history(True)\n",
    "ges.create_genotypes()\n",
    "print ges.run()\n",
    "print ges.fitness_list.sorted()\n",
    "print\n",
    "print\n",
    "gene = ges.population[ges.fitness_list.best_member()]\n",
    "print gene.get_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print ges.get_best_member().get_program()\n",
    "\n",
    "# plt.plot(ges.get_fitness_history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math \n",
    "print math.exp(1)\n",
    "print math.log(2.72)\n",
    "print math.sin(0)\n",
    "print math.cos(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyneurgen.genotypes import Genotype\n",
    "\n",
    "# g = Genotype(10,20,3)\n",
    "# g.local_bnf\n",
    "# g.decimal_gene\n",
    "# g.compute_fitness()\n",
    "\n",
    "ges.set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval(t):\n",
    "    \"\"\"pre:  t  is a TREE, \n",
    "             where TREE ::= NUMERAL | [ OP, TREE, TREE ]\n",
    "                   OP ::=  \"+\" | \"-\"\n",
    "                   NUMERAL ::=  a string of digits\n",
    "       post: ans  is the numerical meaning of t\n",
    "       returns: ans\n",
    "    \"\"\"\n",
    "    if isinstance(t, str) and t.isdigit():  # is  t  a string holding an int?\n",
    "        ans = int(t)  # cast the string to an int\n",
    "    else:  # t is a list, [op, t1, t2]\n",
    "        op = t[0]\n",
    "        t1 = t[1]\n",
    "        t2 = t[2]\n",
    "        ans1 = eval(t1)\n",
    "        # assert:  ans1  is the numerical meaning of t1\n",
    "        ans2 = eval(t2)\n",
    "        # assert:  ans2  is the numerical meaning of t2\n",
    "        if op == \"+\":\n",
    "            ans = ans1 + ans2\n",
    "        elif op == \"-\":\n",
    "            ans = ans1 - ans2\n",
    "        else:  # something's wrong with argument  t !\n",
    "            print \"eval error:\", t, \"is illegal\"\n",
    "            raise Exception  # stops the program\n",
    "    return ans\n",
    "\n",
    "eval([\"-\", [\"+\", \"2\", \"1\"], [\"-\", \"3\", \"4\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def postfix(t):\n",
    "    \"\"\"pre:  t  is a TREE,  where TREE ::= NUM | [ OP, TREE, TREE ]\n",
    "       post: ans  is a string holding a postfix (operator-last) sequence\n",
    "             of the symbols within  t\n",
    "       returns:  ans\n",
    "    \"\"\"\n",
    "    if isinstance(t, str) and t.isdigit():  # is  t  a string holding an int?\n",
    "        ans = t  #(*)  the postfix of a NUM is just the NUM itself \n",
    "    else:  # t is a list, [op, t1, t2]\n",
    "        op = t[0]\n",
    "        t1 = t[1]\n",
    "        t2 = t[2]\n",
    "        ans1 = postfix(t1)\n",
    "        # assert:  ans1  is a string holding the postfix form of t1\n",
    "        ans2 = postfix(t2)\n",
    "        # assert:  ans2  is a string holding the postfix form of t2\n",
    "        # concatenate the subanswers into one string:\n",
    "        if op == \"+\":\n",
    "            ans = ans1 + ans2 + \"+\"  #(*)\n",
    "        elif op == \"-\":\n",
    "            ans = ans1 + ans2 + \"-\"  #(*)\n",
    "        else:\n",
    "            print \"error:\", t, \"is illegal\"\n",
    "            raise Exception  # stops the program\n",
    "    return ans\n",
    "\n",
    "postfix([\"+\", [\"-\", \"2\", \"1\"], \"4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class Grammar(object):\n",
    "    def __init__(self, filename):\n",
    "        self.regex = re.compile(\"<([-\\w]+?)>\")\n",
    "        self.tokens = {}\n",
    "        self._process_file(filename)\n",
    "        self._dims = {}\n",
    "        for x in self.tokens.keys():\n",
    "            self._dims[x] = len(self.tokens[x])\n",
    "\n",
    "    def _process_file(self, filename):\n",
    "        self._cur_token = \"\"\n",
    "        file = open(filename)\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            self._process_line(line)\n",
    "\n",
    "    def _process_line(self, line):\n",
    "        line = line.strip()\n",
    "        if \"::=\" in line:\n",
    "            split_rule = line.partition(\"::=\")\n",
    "            self._cur_token = split_rule[0].strip()\n",
    "            line = split_rule[2].strip()\n",
    "        self._process_rules(line)\n",
    "\n",
    "    def _process_rules(self, rules):\n",
    "        for rule in rules.split(\"|\"):\n",
    "            rule = rule.strip()\n",
    "            try:\n",
    "                if rule:\n",
    "                    self.tokens[self._cur_token].append(rule)\n",
    "            except KeyError:\n",
    "                self.tokens[self._cur_token] = []\n",
    "                self.tokens[self._cur_token].append(rule)\n",
    "\n",
    "    def _replace(self, expr, match, codon):\n",
    "        rep_str = self.tokens[match][codon % self._dims[match]]\n",
    "        return expr.replace(match, rep_str, 1)\n",
    "\n",
    "    def expand(self, genome, expr=\"<start>\"):\n",
    "        \"\"\"This function expands a string using the loaded grammar\n",
    "       and passed genome.  The default grammar symbol is <start>,\n",
    "       but an alternate start string can be passed in after the\n",
    "       genome.\"\"\"\n",
    "        l_gen = len(genome)\n",
    "        if not l_gen:\n",
    "            raise ValueError, \"Empty array passed for genome\"\n",
    "        new_expr = expr\n",
    "        idx = 0\n",
    "        x = self.regex.search(new_expr)\n",
    "        while x:\n",
    "            new_expr = self._replace(new_expr, x.group(0), genome[idx])\n",
    "            idx += 1\n",
    "            if idx >= l_gen:\n",
    "                idx %= l_gen\n",
    "            x = self.regex.search(new_expr)\n",
    "        return new_expr\n",
    "    \n",
    "\n",
    "\n",
    "s = \"\"\"\n",
    "<alpha> ::= <greeting> <noun> | <greeting> and <greeting> <noun>\n",
    "\n",
    "<greeting> ::= Hello | Yarr | Goodbye\n",
    "\n",
    "<noun> ::=  World | Mars\n",
    "\"\"\"\n",
    "\n",
    "# g = Grammar(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "# PonyGE\n",
    "# Copyright (c) 2009 Erik Hemberg and James McDermott\n",
    "# Hereby licensed under the GNU GPL v3.\n",
    "\"\"\" Small GE implementation \"\"\"\n",
    "\n",
    "import sys, copy, re, random, math, operator\n",
    "\n",
    "\n",
    "class Grammar(object):\n",
    "    \"\"\" Context Free Grammar \"\"\"\n",
    "    NT = \"NT\"  # Non Terminal\n",
    "    T = \"T\"  # Terminal\n",
    "\n",
    "    def __init__(self, grammar):\n",
    "        self.rules = {}\n",
    "        self.non_terminals, self.terminals = set(), set()\n",
    "        self.start_rule = None\n",
    "\n",
    "        self.read_bnf(grammar)\n",
    "\n",
    "    def read_bnf(self, grammar):\n",
    "        \"\"\"Read a grammar file in BNF format\"\"\"\n",
    "        # <.+?> Non greedy match of anything between brackets\n",
    "        non_terminal_pattern = \"(<.+?>)\"\n",
    "        rule_separator = \"::=\"\n",
    "        production_separator = \"|\"\n",
    "\n",
    "        # Read the grammar file\n",
    "        for line in grammar.splitlines():\n",
    "            if not line.startswith(\"#\") and line.strip() != \"\":\n",
    "                # Split rules. Everything must be on one line\n",
    "                if line.find(rule_separator):\n",
    "                    lhs, productions = line.split(rule_separator)\n",
    "                    lhs = lhs.strip()\n",
    "                    if not re.search(non_terminal_pattern, lhs):\n",
    "                        raise ValueError(\"lhs is not a NT:\", lhs)\n",
    "                    self.non_terminals.add(lhs)\n",
    "                    if self.start_rule == None:\n",
    "                        self.start_rule = (lhs, self.NT)\n",
    "                    # Find terminals\n",
    "                    tmp_productions = []\n",
    "                    for production in [\n",
    "                            production.strip()\n",
    "                            for production in productions.split(\n",
    "                                production_separator)\n",
    "                    ]:\n",
    "                        tmp_production = []\n",
    "                        if not re.search(non_terminal_pattern, production):\n",
    "                            self.terminals.add(production)\n",
    "                            tmp_production.append((production, self.T))\n",
    "                        else:\n",
    "                            # Match non terminal or terminal pattern\n",
    "                            # TODO does this handle quoted NT symbols?\n",
    "                            for value in re.findall(\"<.+?>|[^<>]*\",\n",
    "                                                    production):\n",
    "                                if value != '':\n",
    "                                    if not re.search(non_terminal_pattern,\n",
    "                                                     value):\n",
    "                                        symbol = (value, self.T)\n",
    "                                        self.terminals.add(value)\n",
    "                                    else:\n",
    "                                        symbol = (value, self.NT)\n",
    "                                    tmp_production.append(symbol)\n",
    "                        tmp_productions.append(tmp_production)\n",
    "                    # Create a rule\n",
    "                    if not lhs in self.rules:\n",
    "                        self.rules[lhs] = tmp_productions\n",
    "                    else:\n",
    "                        raise ValueError(\"lhs should be unique\", lhs)\n",
    "                else:\n",
    "                    raise ValueError(\"Each rule must be on one line\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s %s %s %s\" % (self.terminals, self.non_terminals, self.rules,\n",
    "                                self.start_rule)\n",
    "\n",
    "    def generate(self, _input, max_wraps=2):\n",
    "        \"\"\"Map input via rules to output. Returns output and used_input\"\"\"\n",
    "        used_input = 0\n",
    "        wraps = 0\n",
    "        output = []\n",
    "        production_choices = []\n",
    "\n",
    "        unexpanded_symbols = [self.start_rule]\n",
    "        print 1, unexpanded_symbols\n",
    "        while (wraps < max_wraps) and (len(unexpanded_symbols) > 0):\n",
    "            # Wrap\n",
    "            if used_input % len(_input) == 0 and \\\n",
    "                    used_input > 0 and \\\n",
    "                    len(production_choices) > 1:\n",
    "                wraps += 1\n",
    "            # Expand a production\n",
    "            current_symbol = unexpanded_symbols.pop(0)\n",
    "            # Set output if it is a terminal\n",
    "            if current_symbol[1] != self.NT:\n",
    "                output.append(current_symbol[0])\n",
    "            else:\n",
    "                production_choices = self.rules[current_symbol[0]]\n",
    "                # Select a production\n",
    "                current_production = _input[used_input % len(_input)] % len(\n",
    "                    production_choices)\n",
    "                # Use an input if there was more then 1 choice\n",
    "                if len(production_choices) > 1:\n",
    "                    used_input += 1\n",
    "                # Derviation order is left to right(depth-first)\n",
    "                unexpanded_symbols = production_choices[\n",
    "                    current_production] + unexpanded_symbols\n",
    "\n",
    "        print 2, unexpanded_symbols\n",
    "        #Not completly expanded\n",
    "        if len(unexpanded_symbols) > 0:\n",
    "            return (None, used_input)\n",
    "\n",
    "        return (\"\".join(output), used_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [('<alpha>', 'NT')]\n",
      "2 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Goodbye and Hello World', 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = \"\"\"\n",
    "    <alpha> ::= <greeting> <noun> | <greeting> and <greeting> <noun>\n",
    "\n",
    "    <greeting> ::= Hello | Yarr | Goodbye\n",
    "\n",
    "    <noun> ::=  World | Mars\n",
    "\"\"\"\n",
    "\n",
    "g = Grammar(grammar)\n",
    "\n",
    "g.generate([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['<op>', '<expr>', '<var>', '<pre_op>'])\n",
      "set(['cos', 'log', ')', '(', '+', '*', '-', '/', 'exp', 'x', 'sin'])\n",
      "1 [('<expr>', 'NT')]\n",
      "2 [('<pre_op>', 'NT'), ('(', 'T'), ('<expr>', 'NT'), (')', 'T'), ('<op>', 'NT'), ('<expr>', 'NT'), (')', 'T'), (')', 'T'), (')', 'T'), ('<op>', 'NT'), ('<expr>', 'NT'), (')', 'T')]\n",
      "(None, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sin, cos, exp, log\n",
    "grammar = \"\"\"\n",
    "<expr>   ::= <expr><op><expr> \\\n",
    "           | (<expr><op><expr>) \\\n",
    "           | <pre_op>(<expr>) \\\n",
    "           | <var>\n",
    "<op>     ::= + | - | * | / \n",
    "<pre_op> ::= sin | cos | exp | log\n",
    "<var>    ::= x \n",
    "\"\"\"\n",
    "\n",
    "g = Grammar(grammar)\n",
    "\n",
    "print g.non_terminals\n",
    "print g.terminals\n",
    "print g.generate([np.random.randint(0,255) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from os import path\n",
    "from socket import gethostname\n",
    "\n",
    "hostname = gethostname().split('.')\n",
    "machine_name = hostname[0]\n",
    "\n",
    "from math import floor\n",
    "from re import match, finditer, DOTALL, MULTILINE\n",
    "from sys import maxsize\n",
    "\n",
    "# from algorithm.parameters import params\n",
    "\n",
    "\"\"\"Algorithm parameters\"\"\"\n",
    "params = {\n",
    "        # Set default step and search loop functions\n",
    "        'SEARCH_LOOP': 'search_loop',\n",
    "        'STEP': 'step',\n",
    "\n",
    "        # Evolutionary Parameters\n",
    "        'POPULATION_SIZE': 500,\n",
    "        'GENERATIONS': 50,\n",
    "        'HILL_CLIMBING_HISTORY': 1000,\n",
    "\n",
    "        # Set optional experiment name\n",
    "        'EXPERIMENT_NAME': None,\n",
    "        # Set default number of runs to be done.\n",
    "        # ONLY USED WITH EXPERIMENT MANAGER.\n",
    "        'RUNS': 1,\n",
    "\n",
    "        # Class of problem\n",
    "        'FITNESS_FUNCTION': \"regression\",\n",
    "        # \"regression\"\n",
    "        # \"string_match\"\n",
    "        # \"classification\"\n",
    "        # \"supervised_learning\"\n",
    "\n",
    "        # Select problem dataset\n",
    "        'DATASET_TRAIN': \"Vladislavleva4/Train.txt\",\n",
    "        'DATASET_TEST': \"Vladislavleva4/Test.txt\",\n",
    "        'DATASET_DELIMITER': None,\n",
    "\n",
    "        # Set grammar file\n",
    "        'GRAMMAR_FILE': \"Vladislavleva4.bnf\",\n",
    "        # \"Vladislavleva4.bnf\"\n",
    "        # \"Keijzer6.bnf\"\n",
    "        # \"Dow.bnf\"\n",
    "        # \"Banknote.bnf\"\n",
    "        # \"letter.bnf\"\n",
    "        # \"supervised_learning.bnf\"\n",
    "\n",
    "        # Select error metric\n",
    "        'ERROR_METRIC': None,\n",
    "        # \"mse\"\n",
    "        # \"mae\"\n",
    "        # \"rmse\"\n",
    "        # \"hinge\"\n",
    "        # \"f1_score\"\n",
    "\n",
    "        'OPTIMIZE_CONSTANTS': False,\n",
    "\n",
    "        # Specify target for target problems\n",
    "        'TARGET': \"ponyge_rocks\",\n",
    "\n",
    "        # Set max sizes of individuals\n",
    "        'MAX_TREE_DEPTH': None,\n",
    "        'MAX_TREE_NODES': None,\n",
    "        'CODON_SIZE': 100000,\n",
    "        'MAX_GENOME_LENGTH': None,\n",
    "        'MAX_WRAPS': 0,\n",
    "\n",
    "        # INITIALISATION\n",
    "        'INITIALISATION': \"operators.initialisation.PI_grow\",\n",
    "        # \"operators.initialisation.uniform_genome\"\n",
    "        # \"operators.initialisation.rhh\"\n",
    "        # \"operators.initialisation.PI_grow\"\n",
    "        'INIT_GENOME_LENGTH': 200,\n",
    "        # Set the maximum geneome length for initialisation.\n",
    "        'MAX_INIT_TREE_DEPTH': 10,\n",
    "        # Set the maximum tree depth for initialisation.\n",
    "        'MIN_INIT_TREE_DEPTH': None,\n",
    "        # Set the minimum tree depth for initialisation.\n",
    "\n",
    "        # SELECTION\n",
    "        'SELECTION': \"operators.selection.tournament\",\n",
    "        # \"operators.selection.tournament\"\n",
    "        # \"operators.selection.truncation\",\n",
    "        'TOURNAMENT_SIZE': 2,\n",
    "        # For tournament selection\n",
    "        'SELECTION_PROPORTION': 0.5,\n",
    "        # For truncation selection\n",
    "        'INVALID_SELECTION': False,\n",
    "        # Allow for selection of invalid individuals during selection process.\n",
    "\n",
    "        # OPERATOR OPTIONS\n",
    "        'WITHIN_USED': True,\n",
    "        # Boolean flag for selecting whether or not mutation is confined to\n",
    "        # within the used portion of the genome. Default set to True.\n",
    "\n",
    "        # CROSSOVER\n",
    "        'CROSSOVER': \"operators.crossover.variable_onepoint\",\n",
    "        # \"operators.crossover.fixed_onepoint\",\n",
    "        # \"operators.crossover.subtree\",\n",
    "        'CROSSOVER_PROBABILITY': 0.75,\n",
    "        'NO_CROSSOVER_INVALIDS': False,\n",
    "        # Prevents crossover from generating invalids.\n",
    "\n",
    "        # MUTATION\n",
    "        'MUTATION': \"operators.mutation.int_flip_per_codon\",\n",
    "        # \"operators.mutation.subtree\",\n",
    "        # \"operators.mutation.int_flip_per_codon\",\n",
    "        # \"operators.mutation.int_flip_per_ind\",\n",
    "        'MUTATION_PROBABILITY': None,\n",
    "        'MUTATION_EVENTS': 1,\n",
    "        'NO_MUTATION_INVALIDS': False,\n",
    "        # Prevents mutation from generating invalids.\n",
    "\n",
    "        # REPLACEMENT\n",
    "        'REPLACEMENT': \"operators.replacement.generational\",\n",
    "        # \"operators.replacement.generational\",\n",
    "        # \"operators.replacement.steady_state\",\n",
    "        'ELITE_SIZE': None,\n",
    "\n",
    "        # DEBUGGING\n",
    "        # Use this to turn on debugging mode. This mode doesn't write any files\n",
    "        # and should be used when you want to test new methods.\n",
    "        'DEBUG': False,\n",
    "\n",
    "        # PRINTING\n",
    "        # Use this to print out basic statistics for each generation to the\n",
    "        # command line.\n",
    "        'VERBOSE': False,\n",
    "        # Use this to prevent anything being printed to the command line.\n",
    "        'SILENT': False,\n",
    "\n",
    "        # SAVING\n",
    "        'SAVE_ALL': False,\n",
    "        # Use this to save the phenotype of the best individual from each\n",
    "        # generation. Can generate a lot of files. DEBUG must be False.\n",
    "        'SAVE_PLOTS': True,\n",
    "        # Saves a plot of the evolution of the best fitness result for each\n",
    "        # generation.\n",
    "\n",
    "        # MULTIPROCESSING\n",
    "        'MULTICORE': False,\n",
    "        # Multiprocessing of phenotype evaluations.\n",
    "        'CORES': cpu_count(),\n",
    "\n",
    "        # STATE SAVING/LOADING\n",
    "        'SAVE_STATE': False,\n",
    "        # Saves the state of the evolutionary run every generation. You can\n",
    "        # specify how often you want to save the state with SAVE_STATE_STEP.\n",
    "        'SAVE_STATE_STEP': 1,\n",
    "        # Specifies how often the state of the current evolutionary run is\n",
    "        # saved (i.e. every n-th generation). Requires int value.\n",
    "        'LOAD_STATE': None,\n",
    "        # Loads an evolutionary run from a saved state. You must specify the\n",
    "        # full file path to the desired state file. Note that state files have\n",
    "        # no file type.\n",
    "\n",
    "        # SEEDING\n",
    "        'SEED_GENOME': None,\n",
    "        # Specify a genome for an individual with which to seed the initial\n",
    "        # population.\n",
    "        'SEED_INDIVIDUAL': None,\n",
    "        # Specify an individual with which to seed the initial population.\n",
    "    \n",
    "        # CACHING\n",
    "        'CACHE': False,\n",
    "        # The cache tracks unique individuals across evolution by saving a\n",
    "        # string of each phenotype in a big list of all phenotypes. Saves all\n",
    "        # fitness information on each individual. Gives you an idea of how much\n",
    "        # repetition is in standard GE/GP.\n",
    "        'LOOKUP_FITNESS': False,\n",
    "        # Uses the cache to look up the fitness of duplicate individuals. CACHE\n",
    "        #  must be set to True if you want to use this.\n",
    "        'LOOKUP_BAD_FITNESS': False,\n",
    "        # Uses the cache to give a bad fitness to duplicate individuals. CACHE\n",
    "        # must be True if you want to use this (obviously)\"\"\"\n",
    "        'MUTATE_DUPLICATES': False,\n",
    "        # Removes duplicate individuals from the population by replacing them\n",
    "        # with mutated versions of the original individual. Hopefully this will\n",
    "        # encourage diversity in the population.\n",
    "\n",
    "        # Set machine name (useful for doing multiple runs)\n",
    "        'MACHINE': machine_name,\n",
    "\n",
    "        # Set Random Seed\n",
    "        'RANDOM_SEED': None,\n",
    "\n",
    "        # Reverse Mapping to GE individual:\n",
    "        'REVERSE_MAPPING_TARGET': None\n",
    "}\n",
    "\n",
    "\n",
    "class Grammar(object):\n",
    "    \"\"\"\n",
    "    Parser for Backus-Naur Form (BNF) Context-Free Grammars.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        \"\"\"\n",
    "        Initialises an instance of the grammar class. This instance is used\n",
    "        to parse a given file_name grammar.\n",
    "        :param file_name: A specified BNF grammar file.\n",
    "        \"\"\"\n",
    "\n",
    "        if file_name.endswith(\"pybnf\"):\n",
    "            # Use python filter for parsing grammar output as grammar output\n",
    "            # contains indented python code.\n",
    "            self.python_mode = True\n",
    "\n",
    "        else:\n",
    "            # No need to filter/interpret grammar output, individual\n",
    "            # phenotypes can be evaluated as normal.\n",
    "            self.python_mode = False\n",
    "\n",
    "        # Initialise empty dict for all production rules in the grammar.\n",
    "        # Initialise empty dict of permutations of solutions possible at\n",
    "        # each derivation tree depth.\n",
    "        self.rules, self.permutations = {}, {}\n",
    "\n",
    "        # Initialise dicts for terminals and non terminals, set params.\n",
    "        self.non_terminals, self.terminals = {}, {}\n",
    "        self.start_rule, self.codon_size = None, params['CODON_SIZE']\n",
    "        self.min_path, self.max_arity, self.min_ramp = None, None, None\n",
    "\n",
    "        # Set regular expressions for parsing BNF grammar.\n",
    "        self.ruleregex = '(?P<rulename><\\S+>)\\s*::=\\s*(?P<production>(?:(?=\\#)\\#[^\\r\\n]*|(?!<\\S+>\\s*::=).+?)+)'\n",
    "        self.productionregex = '(?=\\#)(?:\\#.*$)|(?!\\#)\\s*(?P<production>(?:[^\\'\\\"\\|\\#]+|\\'.*?\\'|\".*?\")+)'\n",
    "        self.productionpartsregex = '\\ *([\\r\\n]+)\\ *|([^\\'\"<\\r\\n]+)|\\'(.*?)\\'|\"(.*?)\"|(?P<subrule><[^>|\\s]+>)|([<]+)'\n",
    "\n",
    "        # Read in BNF grammar, set production rules, terminals and\n",
    "        # non-terminals.\n",
    "        self.read_bnf_file(file_name)\n",
    "\n",
    "        # Check the minimum depths of all non-terminals in the grammar.\n",
    "        self.check_depths()\n",
    "\n",
    "        # Check which non-terminals are recursive.\n",
    "        self.check_recursion(self.start_rule[\"symbol\"], [])\n",
    "\n",
    "        # Set the minimum path and maximum arity of the grammar.\n",
    "        self.set_arity()\n",
    "\n",
    "        # Generate lists of recursive production choices and shortest\n",
    "        # terminating path production choices for each NT in the grammar.\n",
    "        # Enables faster tree operations.\n",
    "        self.set_grammar_properties()\n",
    "\n",
    "        # Calculate the total number of derivation tree permutations and\n",
    "        # combinations that can be created by a grammar at a range of depths.\n",
    "        self.check_permutations()\n",
    "\n",
    "        if params['MIN_INIT_TREE_DEPTH']:\n",
    "            # Set the minimum ramping tree depth from the command line.\n",
    "            self.min_ramp = params['MIN_INIT_TREE_DEPTH']\n",
    "\n",
    "        elif hasattr(params['INITIALISATION'], \"ramping\"):\n",
    "            # Set the minimum depth at which ramping can start where we can\n",
    "            # have unique solutions (no duplicates).\n",
    "            self.get_min_ramp_depth()\n",
    "\n",
    "        if params['REVERSE_MAPPING_TARGET']:\n",
    "            # Initialise dicts for reverse-mapping GE individuals.\n",
    "            self.concat_NTs, self.climb_NTs = {}, {}\n",
    "\n",
    "            # Find production choices which can be used to concatenate\n",
    "            # subtrees.\n",
    "            self.find_concatination_NTs()\n",
    "\n",
    "    def read_bnf_file(self, file_name):\n",
    "        \"\"\"\n",
    "        Read a grammar file in BNF format. Parses the grammar and saves a\n",
    "        dict of all production rules and their possible choices.\n",
    "        :param file_name: A specified BNF grammar file.\n",
    "        :return: Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(file_name, 'r') as bnf:\n",
    "            # Read the whole grammar file.\n",
    "            content = bnf.read()\n",
    "\n",
    "            for rule in finditer(self.ruleregex, content, DOTALL):\n",
    "                # Find all rules in the grammar\n",
    "\n",
    "                if self.start_rule is None:\n",
    "                    # Set the first rule found as the start rule.\n",
    "                    self.start_rule = {\n",
    "                        \"symbol\": rule.group('rulename'),\n",
    "                        \"type\": \"NT\"\n",
    "                    }\n",
    "\n",
    "                # Create and add a new rule.\n",
    "                self.non_terminals[rule.group('rulename')] = {\n",
    "                    'id': rule.group('rulename'),\n",
    "                    'min_steps': maxsize,\n",
    "                    'expanded': False,\n",
    "                    'recursive': True,\n",
    "                    'b_factor': 0\n",
    "                }\n",
    "\n",
    "                # Initialise empty list of all production choices for this\n",
    "                # rule.\n",
    "                tmp_productions = []\n",
    "\n",
    "                for p in finditer(self.productionregex,\n",
    "                                  rule.group('production'), MULTILINE):\n",
    "                    # Iterate over all production choices for this rule.\n",
    "                    # Split production choices of a rule.\n",
    "\n",
    "                    if p.group('production') is None or p.group(\n",
    "                            'production').isspace():\n",
    "                        # Skip to the next iteration of the loop if the\n",
    "                        # current \"p\" production is None or blank space.\n",
    "                        continue\n",
    "\n",
    "                    # Initialise empty data structures for production choice\n",
    "                    tmp_production, terminalparts = [], None\n",
    "\n",
    "                    # special case: GERANGE:dataset_n_vars will be transformed\n",
    "                    # to productions 0 | 1 | ... | n_vars-1\n",
    "                    GE_RANGE_regex = r'GE_RANGE:(?P<range>\\w*)'\n",
    "                    m = match(GE_RANGE_regex, p.group('production'))\n",
    "                    if m:\n",
    "                        try:\n",
    "                            if m.group('range') == \"dataset_n_vars\":\n",
    "                                # set n = number of columns from dataset\n",
    "                                n = params['FITNESS_FUNCTION'].n_vars\n",
    "                            else:\n",
    "                                # assume it's just an int\n",
    "                                n = int(m.group('range'))\n",
    "                        except (ValueError, AttributeError):\n",
    "                            raise ValueError(\"Bad use of GE_RANGE: \" + m.group(\n",
    "                            ))\n",
    "\n",
    "                        for i in range(n):\n",
    "                            # add a terminal symbol\n",
    "                            tmp_production, terminalparts = [], None\n",
    "                            symbol = {\n",
    "                                \"symbol\": str(i),\n",
    "                                \"type\": \"T\",\n",
    "                                \"min_steps\": 0,\n",
    "                                \"recursive\": False\n",
    "                            }\n",
    "                            tmp_production.append(symbol)\n",
    "                            if str(i) not in self.terminals:\n",
    "                                self.terminals[str(i)] = \\\n",
    "                                    [rule.group('rulename')]\n",
    "                            elif rule.group('rulename') not in \\\n",
    "                                self.terminals[str(i)]:\n",
    "                                self.terminals[str(i)].append(\n",
    "                                    rule.group('rulename'))\n",
    "                            tmp_productions.append({\n",
    "                                \"choice\": tmp_production,\n",
    "                                \"recursive\": False,\n",
    "                                \"NT_kids\": False\n",
    "                            })\n",
    "                        # don't try to process this production further\n",
    "                        # (but later productions in same rule will work)\n",
    "                        continue\n",
    "\n",
    "                    for sub_p in finditer(self.productionpartsregex,\n",
    "                                          p.group('production').strip()):\n",
    "                        # Split production into terminal and non terminal\n",
    "                        # symbols.\n",
    "\n",
    "                        if sub_p.group('subrule'):\n",
    "                            if terminalparts is not None:\n",
    "                                # Terminal symbol is to be appended to the\n",
    "                                # terminals dictionary.\n",
    "                                symbol = {\n",
    "                                    \"symbol\": terminalparts,\n",
    "                                    \"type\": \"T\",\n",
    "                                    \"min_steps\": 0,\n",
    "                                    \"recursive\": False\n",
    "                                }\n",
    "                                tmp_production.append(symbol)\n",
    "                                if terminalparts not in self.terminals:\n",
    "                                    self.terminals[terminalparts] = \\\n",
    "                                        [rule.group('rulename')]\n",
    "                                elif rule.group('rulename') not in \\\n",
    "                                    self.terminals[terminalparts]:\n",
    "                                    self.terminals[terminalparts].append(\n",
    "                                        rule.group('rulename'))\n",
    "                                terminalparts = None\n",
    "\n",
    "                            tmp_production.append({\n",
    "                                \"symbol\": sub_p.group('subrule'),\n",
    "                                \"type\": \"NT\"\n",
    "                            })\n",
    "\n",
    "                        else:\n",
    "                            # Unescape special characters (\\n, \\t etc.)\n",
    "                            if terminalparts is None:\n",
    "                                terminalparts = ''\n",
    "                            terminalparts += ''.join([\n",
    "                                part.encode().decode('unicode-escape')\n",
    "                                for part in sub_p.groups() if part\n",
    "                            ])\n",
    "\n",
    "                    if terminalparts is not None:\n",
    "                        # Terminal symbol is to be appended to the terminals\n",
    "                        # dictionary.\n",
    "                        symbol = {\n",
    "                            \"symbol\": terminalparts,\n",
    "                            \"type\": \"T\",\n",
    "                            \"min_steps\": 0,\n",
    "                            \"recursive\": False\n",
    "                        }\n",
    "                        tmp_production.append(symbol)\n",
    "                        if terminalparts not in self.terminals:\n",
    "                            self.terminals[terminalparts] = \\\n",
    "                                [rule.group('rulename')]\n",
    "                        elif rule.group('rulename') not in \\\n",
    "                            self.terminals[terminalparts]:\n",
    "                            self.terminals[terminalparts].append(\n",
    "                                rule.group('rulename'))\n",
    "                    tmp_productions.append({\n",
    "                        \"choice\": tmp_production,\n",
    "                        \"recursive\": False,\n",
    "                        \"NT_kids\": False\n",
    "                    })\n",
    "\n",
    "                if not rule.group('rulename') in self.rules:\n",
    "                    # Add new production rule to the rules dictionary if not\n",
    "                    # already there.\n",
    "                    self.rules[rule.group('rulename')] = {\n",
    "                        \"choices\": tmp_productions,\n",
    "                        \"no_choices\": len(tmp_productions)\n",
    "                    }\n",
    "\n",
    "                    if len(tmp_productions) == 1:\n",
    "                        # Unit productions.\n",
    "                        print(\"Warning: Grammar contains unit production \"\n",
    "                              \"for production rule\", rule.group('rulename'))\n",
    "                        print(\"       Unit productions consume GE codons.\")\n",
    "                else:\n",
    "                    # Conflicting rules with the same name.\n",
    "                    raise ValueError(\"lhs should be unique\",\n",
    "                                     rule.group('rulename'))\n",
    "\n",
    "    def check_depths(self):\n",
    "        \"\"\"\n",
    "        Run through a grammar and find out the minimum distance from each\n",
    "        NT to the nearest T. Useful for initialisation methods where we\n",
    "        need to know how far away we are from fully expanding a tree\n",
    "        relative to where we are in the tree and what the depth limit is.\n",
    "        :return: Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialise graph and counter for checking minimum steps to Ts for\n",
    "        # each NT.\n",
    "        counter, graph = 1, []\n",
    "\n",
    "        for rule in sorted(self.rules.keys()):\n",
    "            # Iterate over all NTs.\n",
    "            choices = self.rules[rule]['choices']\n",
    "\n",
    "            # Set branching factor for each NT.\n",
    "            self.non_terminals[rule]['b_factor'] = self.rules[rule][\n",
    "                'no_choices']\n",
    "\n",
    "            for choice in choices:\n",
    "                # Add a new edge to our graph list.\n",
    "                graph.append([rule, choice['choice']])\n",
    "\n",
    "        while graph:\n",
    "            removeset = set()\n",
    "            for edge in graph:\n",
    "                # Find edges which either connect to terminals or nodes\n",
    "                # which are fully expanded.\n",
    "                if all([\n",
    "                        sy[\"type\"] == \"T\" or\n",
    "                        self.non_terminals[sy[\"symbol\"]]['expanded']\n",
    "                        for sy in edge[1]\n",
    "                ]):\n",
    "                    removeset.add(edge[0])\n",
    "\n",
    "            for s in removeset:\n",
    "                # These NTs are now expanded and have their correct minimum\n",
    "                # path set.\n",
    "                self.non_terminals[s]['expanded'] = True\n",
    "                self.non_terminals[s]['min_steps'] = counter\n",
    "\n",
    "            # Create new graph list and increment counter.\n",
    "            graph = [e for e in graph if e[0] not in removeset]\n",
    "            counter += 1\n",
    "\n",
    "    def check_recursion(self, cur_symbol, seen):\n",
    "        \"\"\"\n",
    "        Traverses the grammar recursively and sets the properties of each rule.\n",
    "        :param cur_symbol: symbol to check.\n",
    "        :param seen: Contains already checked symbols in the current traversal.\n",
    "        :return: Boolean stating whether or not cur_symbol is recursive.\n",
    "        \"\"\"\n",
    "\n",
    "        if cur_symbol not in self.non_terminals.keys():\n",
    "            # Current symbol is a T.\n",
    "            return False\n",
    "\n",
    "        if cur_symbol in seen:\n",
    "            # Current symbol has already been seen, is recursive.\n",
    "            return True\n",
    "\n",
    "        # Append current symbol to seen list.\n",
    "        seen.append(cur_symbol)\n",
    "\n",
    "        # Get choices of current symbol.\n",
    "        choices = self.rules[cur_symbol]['choices']\n",
    "        nt = self.non_terminals[cur_symbol]\n",
    "\n",
    "        recursive = False\n",
    "        for choice in choices:\n",
    "            for sym in choice['choice']:\n",
    "                # Recurse over choices.\n",
    "                recursive_symbol = self.check_recursion(sym[\"symbol\"], seen)\n",
    "                recursive = recursive or recursive_symbol\n",
    "\n",
    "        # Set recursive properties.\n",
    "        nt['recursive'] = recursive\n",
    "        seen.remove(cur_symbol)\n",
    "\n",
    "        return nt['recursive']\n",
    "\n",
    "    def set_arity(self):\n",
    "        \"\"\"\n",
    "        Set the minimum path of the grammar, i.e. the smallest legal\n",
    "        solution that can be generated.\n",
    "        Set the maximum arity of the grammar, i.e. the longest path to a\n",
    "        terminal from any non-terminal.\n",
    "        :return: Nothing\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the minimum path of the grammar as the minimum steps to a\n",
    "        # terminal from the start rule.\n",
    "        self.min_path = self.non_terminals[self.start_rule[\"symbol\"]][\n",
    "            'min_steps']\n",
    "\n",
    "        # Initialise the maximum arity of the grammar to 0.\n",
    "        self.max_arity = 0\n",
    "\n",
    "        # Find the maximum arity of the grammar.\n",
    "        for NT in self.non_terminals:\n",
    "            if self.non_terminals[NT]['min_steps'] > self.max_arity:\n",
    "                # Set the maximum arity of the grammar as the longest path\n",
    "                # to a T from any NT.\n",
    "                self.max_arity = self.non_terminals[NT]['min_steps']\n",
    "\n",
    "        # Add the minimum terminal path to each production rule.\n",
    "        for rule in self.rules:\n",
    "            for choice in self.rules[rule]['choices']:\n",
    "                NT_kids = [i for i in choice['choice'] if i[\"type\"] == \"NT\"]\n",
    "                if NT_kids:\n",
    "                    choice['NT_kids'] = True\n",
    "                    for sym in NT_kids:\n",
    "                        sym['min_steps'] = self.non_terminals[sym[\"symbol\"]][\n",
    "                            'min_steps']\n",
    "\n",
    "        # Add boolean flag indicating recursion to each production rule.\n",
    "        for rule in self.rules:\n",
    "            for prod in self.rules[rule]['choices']:\n",
    "                for sym in [i for i in prod['choice'] if i[\"type\"] == \"NT\"]:\n",
    "                    sym['recursive'] = self.non_terminals[sym[\"symbol\"]][\n",
    "                        'recursive']\n",
    "                    if sym['recursive']:\n",
    "                        prod['recursive'] = True\n",
    "\n",
    "    def set_grammar_properties(self):\n",
    "        \"\"\"\n",
    "        Goes through all non-terminals and finds the production choices with\n",
    "        the minimum steps to terminals and with recursive steps.\n",
    "        :return: Nothing\n",
    "        \"\"\"\n",
    "\n",
    "        for nt in self.non_terminals:\n",
    "            # Loop over all non terminals.\n",
    "            # Find the production choices for the current NT.\n",
    "            choices = self.rules[nt]['choices']\n",
    "\n",
    "            for choice in choices:\n",
    "                # Set the maximum path to a terminal for each produciton choice\n",
    "                choice['max_path'] = max(\n",
    "                    [item[\"min_steps\"] for item in choice['choice']])\n",
    "\n",
    "            # Find shortest path to a terminal for all production choices for\n",
    "            # the current NT. The shortest path will be the minimum of the\n",
    "            # maximum paths to a T for each choice over all chocies.\n",
    "            min_path = min([choice['max_path'] for choice in choices])\n",
    "\n",
    "            # Set the minimum path in the self.non_terminals dict.\n",
    "            self.non_terminals[nt]['min_path'] = [\n",
    "                choice for choice in choices if choice['max_path'] == min_path\n",
    "            ]\n",
    "\n",
    "            # Find recursive production choices for current NT. If any\n",
    "            # constituent part of a production choice is recursive,\n",
    "            # it is added to the recursive list.\n",
    "            self.non_terminals[nt]['recursive'] = [\n",
    "                choice for choice in choices if choice['recursive']\n",
    "            ]\n",
    "\n",
    "    def check_permutations(self, ramps=5):\n",
    "        \"\"\"\n",
    "        Calculates how many possible derivation tree combinations can be\n",
    "        created from the given grammar at a specified depth. Only returns\n",
    "        possible combinations at the specific given depth (if there are no\n",
    "        possible permutations for a given depth, will return 0).\n",
    "        :param ramps: The number of depths permutations are calculated for\n",
    "        (starting from the minimum path of the grammar)\n",
    "        :return: Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        perms_list = []\n",
    "        if self.max_arity > self.min_path:\n",
    "            for i in range(max((self.max_arity + 1 - self.min_path), ramps)):\n",
    "                x = self.check_all_permutations(i + self.min_path)\n",
    "                perms_list.append(x)\n",
    "                if i > 0:\n",
    "                    perms_list[i] -= sum(perms_list[:i])\n",
    "                    self.permutations[i + self.min_path] -= sum(perms_list[:i])\n",
    "        else:\n",
    "            for i in range(ramps):\n",
    "                x = self.check_all_permutations(i + self.min_path)\n",
    "                perms_list.append(x)\n",
    "                if i > 0:\n",
    "                    perms_list[i] -= sum(perms_list[:i])\n",
    "                    self.permutations[i + self.min_path] -= sum(perms_list[:i])\n",
    "\n",
    "    def check_all_permutations(self, depth):\n",
    "        \"\"\"\n",
    "        Calculates how many possible derivation tree combinations can be\n",
    "        created from the given grammar at a specified depth. Returns all\n",
    "        possible combinations at the specific given depth including those\n",
    "        depths below the given depth.\n",
    "        :param depth: A depth for which to calculate the number of\n",
    "        permutations of solution that can be generated by the grammar.\n",
    "        :return: The permutations possible at the given depth.\n",
    "        \"\"\"\n",
    "\n",
    "        if depth < self.min_path:\n",
    "            # There is a bug somewhere that is looking for a tree smaller than\n",
    "            # any we can create\n",
    "            s = \"representation.grammar.Grammar.check_all_permutations\\n\" \\\n",
    "                \"Error: cannot check permutations for tree smaller than the \" \\\n",
    "                \"minimum size.\"\n",
    "            raise Exception(s)\n",
    "\n",
    "        if depth in self.permutations.keys():\n",
    "            # We have already calculated the permutations at the requested\n",
    "            # depth.\n",
    "            return self.permutations[depth]\n",
    "\n",
    "        else:\n",
    "            # Calculate permutations at the requested depth.\n",
    "            # Initialise empty data arrays.\n",
    "            pos, depth_per_symbol_trees, productions = 0, {}, []\n",
    "\n",
    "            for NT in self.non_terminals:\n",
    "                # Iterate over all non-terminals to fill out list of\n",
    "                # productions which contain non-terminal choices.\n",
    "                a = self.non_terminals[NT]\n",
    "\n",
    "                for rule in self.rules[a['id']]['choices']:\n",
    "                    if rule['NT_kids']:\n",
    "                        productions.append(rule)\n",
    "\n",
    "            # Get list of all production choices from the start symbol.\n",
    "            start_symbols = self.rules[self.start_rule[\"symbol\"]]['choices']\n",
    "\n",
    "            for choice in productions:\n",
    "                # Generate a list of the symbols of each production choice\n",
    "                key = str([sym['symbol'] for sym in choice['choice']])\n",
    "\n",
    "                # Initialise permutations dictionary with the list\n",
    "                depth_per_symbol_trees[key] = {}\n",
    "\n",
    "            for i in range(2, depth + 1):\n",
    "                # Find all the possible permutations from depth of min_path up\n",
    "                # to a specified depth\n",
    "\n",
    "                for choice in productions:\n",
    "                    # Iterate over all production choices\n",
    "                    sym_pos = 1\n",
    "\n",
    "                    for j in choice['choice']:\n",
    "                        # Iterate over all symbols in a production choice.\n",
    "                        symbol_arity_pos = 0\n",
    "\n",
    "                        if j[\"type\"] is \"NT\":\n",
    "                            # We are only interested in non-terminal symbols\n",
    "                            for child in self.rules[j[\"symbol\"]]['choices']:\n",
    "                                # Iterate over all production choices for\n",
    "                                # each NT symbol in the original choice.\n",
    "\n",
    "                                if len(child['choice']) == 1 and \\\n",
    "                                   child['choice'][0][\"type\"] == \"T\":\n",
    "                                    # If the child choice leads directly to\n",
    "                                    # a single terminal, increment the\n",
    "                                    # permutation count.\n",
    "                                    symbol_arity_pos += 1\n",
    "\n",
    "                                else:\n",
    "                                    # The child choice does not lead\n",
    "                                    # directly to a single terminal.\n",
    "                                    # Generate a key for the permutations\n",
    "                                    # dictionary and increment the\n",
    "                                    # permutations count there.\n",
    "                                    key = [\n",
    "                                        sym['symbol']\n",
    "                                        for sym in child['choice']\n",
    "                                    ]\n",
    "                                    if (i - 1) in depth_per_symbol_trees[str(\n",
    "                                            key)].keys():\n",
    "                                        symbol_arity_pos += depth_per_symbol_trees[\n",
    "                                            str(key)][i - 1]\n",
    "\n",
    "                            # Multiply original count by new count.\n",
    "                            sym_pos *= symbol_arity_pos\n",
    "\n",
    "                    # Generate new key for the current production choice and\n",
    "                    # set the new value in the permutations dictionary.\n",
    "                    key = [sym['symbol'] for sym in choice['choice']]\n",
    "                    depth_per_symbol_trees[str(key)][i] = sym_pos\n",
    "\n",
    "            # Calculate permutations for the start symbol.\n",
    "            for sy in start_symbols:\n",
    "                key = [sym['symbol'] for sym in sy['choice']]\n",
    "                if str(key) in depth_per_symbol_trees:\n",
    "                    pos += depth_per_symbol_trees[str(key)][\n",
    "                        depth] if depth in depth_per_symbol_trees[str(\n",
    "                            key)] else 0\n",
    "                else:\n",
    "                    pos += 1\n",
    "\n",
    "            # Set the overall permutations dictionary for the current depth.\n",
    "            self.permutations[depth] = pos\n",
    "\n",
    "            return pos\n",
    "\n",
    "    def get_min_ramp_depth(self):\n",
    "        \"\"\"\n",
    "        Find the minimum depth at which ramping can start where we can have\n",
    "        unique solutions (no duplicates).\n",
    "        :param self: An instance of the representation.grammar.grammar class.\n",
    "        :return: The minimum depth at which unique solutions can be generated\n",
    "        \"\"\"\n",
    "\n",
    "        max_tree_depth = params['MAX_INIT_TREE_DEPTH']\n",
    "        size = params['POPULATION_SIZE']\n",
    "\n",
    "        # Specify the range of ramping depths\n",
    "        depths = range(self.min_path, max_tree_depth + 1)\n",
    "\n",
    "        if size % 2:\n",
    "            # Population size is odd\n",
    "            size += 1\n",
    "\n",
    "        if size / 2 < len(depths):\n",
    "            # The population size is too small to fully cover all ramping\n",
    "            # depths. Only ramp to the number of depths we can reach.\n",
    "            depths = depths[:int(size / 2)]\n",
    "\n",
    "        # Find the minimum number of unique solutions required to generate\n",
    "        # sufficient individuals at each depth.\n",
    "        unique_start = int(floor(size / len(depths)))\n",
    "        ramp = None\n",
    "\n",
    "        for i in sorted(self.permutations.keys()):\n",
    "            # Examine the number of permutations and combinations of unique\n",
    "            # solutions capable of being generated by a grammar across each\n",
    "            # depth i.\n",
    "            if self.permutations[i] > unique_start:\n",
    "                # If the number of permutations possible at a given depth i is\n",
    "                # greater than the required number of unique solutions,\n",
    "                # set the minimum ramp depth and break out of the loop.\n",
    "                ramp = i\n",
    "                break\n",
    "        self.min_ramp = ramp\n",
    "\n",
    "    def find_concatination_NTs(self):\n",
    "        \"\"\"\n",
    "        Scour the grammar class to find non-terminals which can be used to\n",
    "        combine/reduce_trees derivation trees. Build up a list of such\n",
    "        non-terminals. A concatenation non-terminal is one in which at least\n",
    "        one production choice contains multiple non-terminals. For example:\n",
    "            <e> ::= (<e><o><e>)|<v>\n",
    "        is a concatenation NT, since the production choice (<e><o><e>) can\n",
    "        reduce_trees multiple NTs together. Note that this choice also includes\n",
    "        a combination of terminals and non-terminals.\n",
    "        :return: Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        # Iterate over all non-terminals/production rules.\n",
    "        for rule in sorted(self.rules.keys()):\n",
    "\n",
    "            # Find rules which have production choices leading to NTs.\n",
    "            concat = [\n",
    "                choice for choice in self.rules[rule]['choices']\n",
    "                if choice['NT_kids']\n",
    "            ]\n",
    "\n",
    "            if concat:\n",
    "                # We can reduce_trees NTs.\n",
    "                for choice in concat:\n",
    "\n",
    "                    symbols = [[sym['symbol'], sym['type']]\n",
    "                               for sym in choice['choice']]\n",
    "\n",
    "                    NTs = [\n",
    "                        sym['symbol'] for sym in choice['choice']\n",
    "                        if sym['type'] == \"NT\"\n",
    "                    ]\n",
    "\n",
    "                    for NT in NTs:\n",
    "                        # We add to our self.concat_NTs dictionary. The key is\n",
    "                        # the root node we want to reduce_trees with another\n",
    "                        # node. This way when we have a node and wish to see\n",
    "                        # if we can reduce_trees it with anything else, we\n",
    "                        # simply look up this dictionary.\n",
    "                        conc = [choice['choice'], rule, symbols]\n",
    "\n",
    "                        if NT not in self.concat_NTs:\n",
    "                            self.concat_NTs[NT] = [conc]\n",
    "                        else:\n",
    "                            if conc not in self.concat_NTs[NT]:\n",
    "                                self.concat_NTs[NT].append(conc)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s %s %s %s\" % (self.terminals, self.non_terminals, self.rules,\n",
    "                                self.start_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Warning: Grammar contains unit production for production rule', '<var>')\n",
      "       Unit productions consume GE codons.\n"
     ]
    }
   ],
   "source": [
    "grammar = \"\"\"\n",
    "<expr>   ::= <expr><op><expr> \\\n",
    "           | (<expr><op><expr>) \\\n",
    "           | <pre_op>(<expr>) \\\n",
    "           | <var>\n",
    "<op>     ::= + | - | * | / \n",
    "<pre_op> ::= sin | cos | exp | log\n",
    "<var>    ::= x \n",
    "\"\"\"\n",
    "\n",
    "g = Grammar('grammar.bnf')\n",
    "\n",
    "# print g.non_terminals\n",
    "# print g.terminals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x', [231, 144, 134, 33, 100, 170, 34, 193, 13, 231], None, 3, False, 3, 2)\n",
      "('x', [127, 180, 161, 24, 65, 37, 28, 195, 250, 61], None, 3, False, 3, 2)\n",
      "('x', [251, 94, 79, 65, 83, 158, 14, 127, 248, 35], None, 3, False, 3, 2)\n",
      "('exp(1.0)', [18, 14, 27, 73, 108, 137, 213, 24, 5, 93], None, 6, False, 4, 4)\n",
      "('(x+x)', [233, 27, 210, 40, 79, 136, 176, 41, 227, 88], None, 9, False, 4, 6)\n",
      "('1.0', [27, 163, 213, 95, 215, 215, 46, 98, 195, 141], None, 3, False, 3, 2)\n",
      "('(1.0+exp(1.0))', [177, 243, 233, 208, 250, 210, 235, 177, 85, 46], None, 12, False, 5, 8)\n",
      "('1.0', [71, 179, 226, 160, 88, 90, 106, 109, 85, 73], None, 3, False, 3, 2)\n",
      "('sin(x+x)', [238, 44, 164, 75, 158, 60, 79, 132, 106, 135], None, 12, False, 5, 8)\n",
      "('x', [203, 138, 254, 218, 189, 89, 110, 111, 254, 7], None, 3, False, 3, 2)\n",
      "('1.0', [247, 71, 174, 179, 192, 135, 94, 242, 242, 90], None, 3, False, 3, 2)\n",
      "('log(x*cos(1.0))', [242, 223, 8, 147, 18, 214, 162, 9, 231, 145], None, 15, False, 6, 10)\n",
      "('1.0*log(1.0)', [128, 179, 45, 70, 226, 51, 95, 137, 148, 121], None, 12, False, 5, 8)\n",
      "('1.0', [59, 159, 240, 84, 235, 207, 207, 238, 19, 168], None, 3, False, 3, 2)\n",
      "('log(1.0)', [174, 71, 67, 23, 222, 92, 45, 66, 216, 154], None, 6, False, 4, 4)\n",
      "('1.0', [63, 5, 222, 175, 135, 69, 196, 71, 215, 138], None, 3, False, 3, 2)\n",
      "('cos(1.0)', [90, 181, 171, 109, 25, 70, 49, 157, 60, 90], None, 6, False, 4, 4)\n",
      "('(x+log(x))', [45, 111, 226, 108, 250, 95, 167, 96, 106, 99], None, 12, False, 5, 8)\n",
      "('cos(x)-1.0', [100, 78, 101, 119, 246, 145, 71, 11, 190, 90], None, 12, False, 5, 8)\n",
      "('x', [167, 188, 90, 33, 192, 221, 113, 213, 239, 36], None, 3, False, 3, 2)\n",
      "('1.0', [231, 67, 82, 96, 148, 22, 230, 158, 254, 12], None, 3, False, 3, 2)\n",
      "('x', [235, 250, 81, 69, 236, 221, 188, 188, 152, 222], None, 3, False, 3, 2)\n",
      "('cos(x)+1.0', [188, 110, 161, 171, 184, 120, 231, 39, 157, 75], None, 12, False, 5, 8)\n",
      "('x', [111, 124, 219, 8, 6, 112, 110, 59, 124, 238], None, 3, False, 3, 2)\n",
      "('(x+1.0)', [37, 51, 186, 252, 183, 33, 190, 1, 235, 217], None, 9, False, 4, 6)\n",
      "('(x/1.0-x)', [33, 203, 6, 223, 40, 179, 135, 121, 111, 196], None, 15, False, 5, 10)\n",
      "('x', [79, 118, 239, 189, 60, 35, 44, 95, 19, 201], None, 3, False, 3, 2)\n",
      "('x', [91, 22, 227, 108, 55, 242, 0, 111, 116, 151], None, 3, False, 3, 2)\n",
      "('log(sin(exp(1.0)))', [246, 39, 178, 72, 222, 10, 231, 163, 148, 82], None, 12, False, 6, 8)\n",
      "('x', [155, 158, 163, 26, 107, 41, 190, 8, 206, 28], None, 3, False, 3, 2)\n",
      "('1.0', [15, 73, 240, 205, 106, 236, 150, 192, 111, 248], None, 3, False, 3, 2)\n",
      "('x', [87, 76, 62, 38, 54, 143, 32, 243, 162, 220], None, 3, False, 3, 2)\n",
      "('1.0', [79, 5, 252, 235, 42, 190, 246, 105, 101, 198], None, 3, False, 3, 2)\n",
      "('x', [251, 176, 138, 192, 81, 57, 147, 166, 142, 229], None, 3, False, 3, 2)\n",
      "('1.0*1.0/1.0', [72, 68, 211, 175, 210, 203, 205, 219, 75, 233], None, 15, False, 5, 10)\n",
      "('x/x', [124, 63, 184, 159, 139, 16, 253, 130, 204, 39], None, 9, False, 4, 6)\n",
      "('cos(sin(x))+x', [120, 174, 221, 138, 12, 51, 28, 16, 115, 64], None, 15, False, 6, 10)\n",
      "('x', [7, 128, 182, 49, 73, 145, 144, 119, 83, 132], None, 3, False, 3, 2)\n",
      "('1.0', [31, 179, 203, 192, 102, 126, 99, 128, 200, 98], None, 3, False, 3, 2)\n",
      "('log(sin(1.0))', [94, 163, 242, 12, 111, 245, 124, 38, 73, 25], None, 9, False, 5, 6)\n",
      "('x', [95, 20, 14, 18, 202, 137, 217, 0, 154, 3], None, 3, False, 3, 2)\n",
      "('log(cos(x))', [170, 27, 234, 181, 127, 222, 176, 97, 95, 236], None, 9, False, 5, 6)\n",
      "('1.0', [63, 55, 1, 51, 204, 243, 70, 116, 184, 194], None, 3, False, 3, 2)\n",
      "('1.0', [55, 193, 63, 16, 228, 37, 184, 146, 122, 160], None, 3, False, 3, 2)\n",
      "('1.0', [203, 211, 31, 191, 81, 115, 113, 89, 223, 136], None, 3, False, 3, 2)\n",
      "('x', [191, 240, 174, 173, 82, 31, 87, 223, 223, 32], None, 3, False, 3, 2)\n",
      "('x', [59, 102, 204, 166, 137, 106, 108, 247, 150, 128], None, 3, False, 3, 2)\n",
      "('x', [119, 48, 178, 6, 107, 10, 11, 105, 245, 247], None, 3, False, 3, 2)\n",
      "('sin(x)/1.0', [196, 90, 68, 79, 216, 163, 43, 245, 237, 205], None, 12, False, 5, 8)\n",
      "('1.0', [127, 215, 83, 229, 102, 88, 90, 206, 92, 18], None, 3, False, 3, 2)\n",
      "('sin(1.0)', [250, 12, 51, 119, 250, 87, 29, 114, 73, 213], None, 6, False, 4, 4)\n",
      "('exp(x)', [134, 226, 175, 238, 202, 58, 228, 213, 69, 225], None, 6, False, 4, 4)\n",
      "('x', [183, 136, 159, 201, 186, 159, 129, 245, 112, 36], None, 3, False, 3, 2)\n",
      "('1.0', [175, 3, 209, 230, 81, 204, 12, 232, 82, 217], None, 3, False, 3, 2)\n",
      "('x', [175, 188, 184, 17, 115, 96, 163, 19, 241, 226], None, 3, False, 3, 2)\n",
      "('sin(exp(1.0))', [222, 192, 218, 150, 103, 183, 51, 184, 35, 68], None, 9, False, 5, 6)\n",
      "('1.0', [191, 247, 130, 40, 165, 70, 124, 127, 188, 42], None, 3, False, 3, 2)\n",
      "('1.0', [207, 83, 212, 56, 235, 19, 179, 225, 158, 193], None, 3, False, 3, 2)\n",
      "('x', [19, 90, 219, 98, 199, 36, 8, 217, 205, 42], None, 3, False, 3, 2)\n",
      "('cos(x)', [150, 97, 211, 2, 52, 143, 218, 191, 42, 219], None, 6, False, 4, 4)\n",
      "('exp(x)', [130, 158, 35, 204, 200, 7, 253, 137, 27, 111], None, 6, False, 4, 4)\n",
      "('x', [23, 180, 150, 27, 4, 85, 237, 205, 69, 190], None, 3, False, 3, 2)\n",
      "('exp(x*x)', [218, 154, 224, 67, 188, 50, 227, 124, 206, 38], None, 12, False, 5, 8)\n",
      "('cos(x)', [238, 245, 63, 118, 107, 195, 139, 84, 136, 220], None, 6, False, 4, 4)\n",
      "('log(1.0)', [38, 139, 107, 173, 196, 6, 30, 167, 251, 33], None, 6, False, 4, 4)\n",
      "('1.0*1.0*x', [232, 199, 155, 202, 176, 75, 247, 18, 83, 202], None, 15, False, 5, 10)\n",
      "('exp(log(x))', [238, 58, 214, 43, 3, 158, 120, 204, 112, 220], None, 9, False, 5, 6)\n",
      "('x', [159, 104, 236, 176, 69, 127, 168, 20, 88, 23], None, 3, False, 3, 2)\n",
      "('1.0', [23, 101, 99, 130, 141, 207, 74, 97, 17, 21], None, 3, False, 3, 2)\n",
      "('(x*log(1.0))', [21, 247, 156, 138, 234, 51, 243, 27, 115, 68], None, 12, False, 5, 8)\n",
      "('1.0', [191, 91, 54, 171, 141, 254, 40, 227, 87, 32], None, 3, False, 3, 2)\n",
      "('x', [23, 158, 200, 217, 197, 199, 165, 227, 31, 41], None, 3, False, 3, 2)\n",
      "('x', [179, 162, 187, 239, 9, 231, 125, 56, 132, 163], None, 3, False, 3, 2)\n",
      "('exp(1.0-x)', [46, 182, 108, 23, 45, 113, 43, 50, 99, 72], None, 12, False, 5, 8)\n",
      "('1.0', [155, 167, 37, 158, 184, 212, 28, 195, 181, 220], None, 3, False, 3, 2)\n",
      "('sin(1.0)', [158, 216, 27, 159, 117, 42, 119, 4, 4, 240], None, 6, False, 4, 4)\n",
      "('x', [227, 58, 120, 94, 23, 183, 72, 193, 21, 230], None, 3, False, 3, 2)\n",
      "('cos(x)', [34, 193, 239, 54, 31, 137, 243, 106, 41, 159], None, 6, False, 4, 4)\n",
      "('1.0', [191, 71, 218, 206, 8, 11, 163, 114, 217, 26], None, 3, False, 3, 2)\n",
      "('1.0', [239, 57, 38, 102, 137, 38, 132, 213, 54, 130], None, 3, False, 3, 2)\n",
      "('1.0', [139, 131, 142, 201, 142, 140, 109, 147, 200, 211], None, 3, False, 3, 2)\n",
      "('exp(x)', [90, 206, 123, 248, 45, 8, 92, 244, 45, 176], None, 6, False, 4, 4)\n",
      "('sin(log(1.0))', [22, 212, 42, 215, 215, 27, 179, 15, 227, 48], None, 9, False, 5, 6)\n",
      "('x', [27, 116, 102, 227, 186, 30, 82, 121, 78, 116], None, 3, False, 3, 2)\n",
      "('1.0', [119, 171, 201, 29, 118, 2, 246, 175, 147, 5], None, 3, False, 3, 2)\n",
      "('cos(1.0)', [122, 89, 47, 179, 178, 32, 223, 149, 113, 51], None, 6, False, 4, 4)\n",
      "('exp(exp(cos(x)))', [166, 218, 50, 150, 246, 29, 11, 220, 0, 69], None, 12, False, 6, 8)\n",
      "('sin(cos(1.0))', [130, 152, 54, 1, 99, 229, 31, 189, 177, 1], None, 9, False, 5, 6)\n",
      "('x', [131, 84, 63, 201, 226, 68, 207, 4, 115, 156], None, 3, False, 3, 2)\n",
      "('1.0', [163, 187, 254, 95, 101, 216, 182, 77, 208, 140], None, 3, False, 3, 2)\n",
      "('1.0', [127, 125, 12, 139, 169, 227, 161, 5, 38, 234], None, 3, False, 3, 2)\n",
      "('1.0', [111, 225, 107, 119, 128, 208, 201, 245, 197, 105], None, 3, False, 3, 2)\n",
      "('1.0', [35, 245, 116, 142, 171, 83, 222, 55, 238, 138], None, 3, False, 3, 2)\n",
      "('1.0', [55, 209, 243, 18, 126, 91, 102, 65, 179, 44], None, 3, False, 3, 2)\n",
      "('cos(x)', [170, 89, 27, 4, 240, 81, 1, 40, 198, 186], None, 6, False, 4, 4)\n",
      "('1.0', [87, 135, 121, 10, 246, 0, 158, 236, 88, 168], None, 3, False, 3, 2)\n",
      "('log(1.0)', [54, 159, 127, 83, 174, 82, 121, 70, 104, 151], None, 6, False, 4, 4)\n",
      "('1.0', [143, 31, 193, 50, 123, 55, 34, 91, 49, 113], None, 3, False, 3, 2)\n",
      "('exp(1.0)', [126, 106, 151, 161, 229, 222, 15, 97, 110, 58], None, 6, False, 4, 4)\n",
      "('cos(x)', [138, 185, 75, 8, 77, 223, 154, 170, 20, 249], None, 6, False, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'PonyGE2/src')\n",
    "\n",
    "import representation as r\n",
    "import algorithm as a\n",
    "import numpy as np\n",
    "\n",
    "def set_up_grammar(g):\n",
    "    f = open(\"grammar.bnf\", \"w\")\n",
    "    f.write(g)\n",
    "    f.close()\n",
    "    \n",
    "set_up_grammar(\"\"\"\n",
    "<expr>   ::= <expr><op><expr> | (<expr><op><expr>) | <pre_op>(<expr>) | <var>\n",
    "<op>     ::= + | - | * | / \n",
    "<pre_op> ::= sin | cos | exp | log\n",
    "<var>    ::= x | 1.0\n",
    "\"\"\")    \n",
    "\n",
    "g = r.grammar.Grammar('grammar.bnf')\n",
    "a.parameters.params['BNF_GRAMMAR'] = g\n",
    "\n",
    "i = 0\n",
    "while i<100:\n",
    "    m = a.mapper.map_ind_from_genome([np.random.randint(0,255) for _ in range(10)])\n",
    "    if m[0]:\n",
    "        i = i + 1\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1.0', 2)\n",
      "('cos(x)+x', 8)\n",
      "('x', 2)\n",
      "('cos(x)', 4)\n",
      "('cos(1.0)', 4)\n",
      "('(x/x)', 6)\n",
      "('cos(cos(1.0))', 6)\n",
      "('1.0', 2)\n",
      "('cos(exp(log(1.0)))', 8)\n",
      "('1.0', 2)\n",
      "('log(1.0)', 4)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('1.0', 2)\n",
      "('cos(cos(x))', 6)\n",
      "('x', 2)\n",
      "('1.0', 2)\n",
      "('cos(cos(x))', 6)\n",
      "('1.0+1.0', 6)\n",
      "('log(1.0)', 4)\n",
      "('log(log(cos(x)))', 8)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('exp(log(x))', 6)\n",
      "('x', 2)\n",
      "('(x/1.0)', 6)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('1.0', 2)\n",
      "('x', 2)\n",
      "('1.0', 2)\n",
      "('x', 2)\n",
      "('log(1.0)', 4)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('1.0', 2)\n",
      "('x', 2)\n",
      "('cos(1.0)', 4)\n",
      "('(1.0+cos(x))', 8)\n",
      "('exp(x)', 4)\n",
      "('(x+1.0)', 6)\n",
      "('cos((1.0+1.0))', 8)\n",
      "('1.0', 2)\n",
      "('x', 2)\n",
      "('cos(x)', 4)\n",
      "('x', 2)\n",
      "('cos(1.0)', 4)\n",
      "('x', 2)\n",
      "('cos(x)', 4)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('exp((x+1.0))', 8)\n",
      "('1.0', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('(1.0-x)', 6)\n",
      "('x', 2)\n",
      "('1.0', 2)\n",
      "('(x-1.0)', 6)\n",
      "('sin(1.0)', 4)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('log(x)', 4)\n",
      "('x', 2)\n",
      "('x*cos(1.0)', 8)\n",
      "('x-x', 6)\n",
      "('sin(x)', 4)\n",
      "('(exp(1.0)/1.0)', 8)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('log(x)', 4)\n",
      "('1.0', 2)\n",
      "('x/x', 6)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('exp(x)', 4)\n",
      "('1.0', 2)\n",
      "('x', 2)\n",
      "('x', 2)\n",
      "('exp(1.0)', 4)\n",
      "('x', 2)\n",
      "('1.0', 2)\n",
      "('1.0', 2)\n",
      "('log(cos(exp(x)))', 8)\n",
      "('1.0', 2)\n",
      "('x', 2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'ponyge-master/src')\n",
    "import numpy as np\n",
    "\n",
    "import ponyge as p\n",
    "\n",
    "\n",
    "g = p.Grammar('grammar.bnf')\n",
    "\n",
    "g.generate([np.random.randint(0,255) for _ in range(10)])\n",
    "\n",
    "\n",
    "i = 0\n",
    "while i<100:\n",
    "    m = g.generate([np.random.randint(0,255) for _ in range(10)])\n",
    "    if m[0]:\n",
    "        i = i + 1\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 5000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "abstract": "TODO: Poner el abstract.",
  "anaconda-cloud": {},
  "author": "Andrés Mañas Mañas",
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "title": "Computación evolutiva: tercera práctica",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "navigate_menu": false,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "403px",
    "left": "1600px",
    "right": "20px",
    "top": "108px",
    "width": "307px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
